{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import os\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from mmocr_eval import eval_ocr_metric\n",
    "import re\n",
    "import cv2 as cv\n",
    "import onnxruntime\n",
    "from torchvision import transforms\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx\n",
    "# !pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load pth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'crnn_30k_lr_25e-2' #folder name of model\n",
    "iteration = 'crnn_30k_lr_25e-2' # model .pth file name\n",
    "\n",
    "model_path = os.path.join('trainer', 'saved_models',model)\n",
    "reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "                    model_storage_directory = model_path,\n",
    "                    user_network_directory = os.path.join('my_model','user_network'),\n",
    "                    recog_network  = iteration,\n",
    "                    config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "                    gpu = True)\n",
    "# reader = easyocr.Reader(lang_list = ['en','th'],gpu = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction with pth model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this cell and edit config in deployment_config.py to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# random_file_path = filepaths[10]\n",
    "random_file_path = random.sample(filepaths,1)[0]\n",
    "\n",
    "img = plt.imread(random_file_path)\n",
    "# print (f'image befor reader: {img[0][0]}')\n",
    "start = time.time()\n",
    "result = reader.recognize(random_file_path)\n",
    "end = time.time()\n",
    "print(f'time: {end - start}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction with onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy()if tensor.requires_grad else tensor.cpu().numpy()\n",
    "def custom_mean(x):\n",
    "    return x.prod()**(2.0/np.sqrt(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_recognize(img_path, ort_session, converter, device = torch.device(\"cuda\")):\n",
    "    # start = time.time()\n",
    "    img, img_cv_grey = reformat_input(img_path)\n",
    "    y_max, x_max = img_cv_grey.shape\n",
    "    horizontal_list = [[0, x_max, 0, y_max]]\n",
    "    for bbox in horizontal_list:\n",
    "                    h_list = [bbox]\n",
    "                    f_list = []\n",
    "                    image_list, max_width = get_image_list(h_list, f_list, img_cv_grey, model_height = 64)\n",
    "\n",
    "    img_list = [item[1] for item in image_list]\n",
    "\n",
    "    AlignCollate_normal = AlignCollate(imgH=64, imgW=600, keep_ratio_with_pad=True)\n",
    "    test_data = ListDataset(img_list)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=1, shuffle=False,\n",
    "            num_workers=int(0), collate_fn=AlignCollate_normal, pin_memory=True)\n",
    "    \n",
    "    image_tensors = next(iter(test_loader))\n",
    "    batch_size = image_tensors.size(0)\n",
    "    image = image_tensors.to(device)\n",
    "    # end = time.time()\n",
    "    # print(f'pre-process : {end - start}')\n",
    "\n",
    "    # start = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    preds = torch.from_numpy(ort_outs[0])\n",
    "    # end = time.time()\n",
    "    # print(f'prediction : {end - start}')\n",
    "\n",
    "    ignore_idx = []\n",
    "    start = time.time()\n",
    "    # Select max probabilty (greedy decoding) then decode index to character\n",
    "    preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "\n",
    "    ######## filter ignore_char, rebalance\n",
    "    preds_prob = F.softmax(preds, dim=2)\n",
    "    preds_prob = preds_prob.cpu().detach().numpy()\n",
    "    preds_prob[:,:,ignore_idx] = 0.\n",
    "    pred_norm = preds_prob.sum(axis=2)\n",
    "    preds_prob = preds_prob/np.expand_dims(pred_norm, axis=-1)\n",
    "    preds_prob = torch.from_numpy(preds_prob).float().to(device)\n",
    "    result = []\n",
    "\n",
    "    # end = time.time()\n",
    "    # print(f'preds_prob : {end - start}')\n",
    "    # decoder\n",
    "    decoder = 'greedy'\n",
    "    if decoder == 'greedy':\n",
    "        # Select max probabilty (greedy decoding) then decode index to character\n",
    "        _, preds_index = preds_prob.max(2)\n",
    "        preds_index = preds_index.view(-1)\n",
    "        preds_str = converter.decode_greedy(preds_index.data.cpu().detach().numpy(), preds_size.data)\n",
    "    elif decoder == 'beamsearch':\n",
    "        k = preds_prob.cpu().detach().numpy()\n",
    "        preds_str = converter.decode_beamsearch(k, beamWidth=5)\n",
    "    elif decoder == 'wordbeamsearch':\n",
    "        k = preds_prob.cpu().detach().numpy()\n",
    "        preds_str = converter.decode_wordbeamsearch(k, beamWidth=5)\n",
    "\n",
    "    # end = time.time()\n",
    "    # print(f'decoder : {end - start}')\n",
    "    preds_prob = preds_prob.cpu().detach().numpy()\n",
    "    values = preds_prob.max(axis=2)\n",
    "    indices = preds_prob.argmax(axis=2)\n",
    "    preds_max_prob = []\n",
    "    for v,i in zip(values, indices):\n",
    "        max_probs = v[i!=0]\n",
    "        if len(max_probs)>0:\n",
    "            preds_max_prob.append(max_probs)\n",
    "        else:\n",
    "            preds_max_prob.append(np.array([0]))\n",
    "\n",
    "    for pred, pred_max_prob in zip(preds_str, preds_max_prob):\n",
    "        confidence_score = custom_mean(pred_max_prob)\n",
    "        result.append([pred, confidence_score])\n",
    "    # end = time.time()\n",
    "    # print(f'post-process : {end - start}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from easyocr.utils import reformat_input\n",
    "from easyocr.utils import get_image_list\n",
    "from easyocr.recognition import AlignCollate\n",
    "from easyocr.recognition import ListDataset\n",
    "import torch.nn.functional as F\n",
    "from easyocr.utils import CTCLabelConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "ort_session = onnxruntime.InferenceSession(\"rosetta_recognitionModel.onnx\", providers=['CUDAExecutionProvider', 'TensorrtExecutionProvider'])\n",
    "ort_session.set_providers(['CUDAExecutionProvider', 'TensorrtExecutionProvider'])\n",
    "ort_session.get_providers()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict with onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_file_path = random.sample(filepaths,1)[0]\n",
    "# import cProfile\n",
    "# # random_file_path = filepaths[0]\n",
    "# start = time.time()\n",
    "# character = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`|~กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืุูเแโใไๅๆ็่้๊๋์ํ๐๑๒๓๔๕๖๗๘๙–‘ ’'\n",
    "# separator_list = {}\n",
    "# dict_list = {'en': 'd:\\\\Intern\\\\EasyOCR\\\\easyocr\\\\dict\\\\en.txt', 'th': 'd:\\\\Intern\\\\EasyOCR\\\\easyocr\\\\dict\\\\th.txt'}\n",
    "# converter = CTCLabelConverter(character, separator_list, dict_list)\n",
    "# result = onnx_recognize(random_file_path, ort_session, converter)\n",
    "\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with 1000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "with open(label_path, encoding='utf8') as file:\n",
    "    label = np.loadtxt(file,dtype=str)\n",
    "start = time.time()\n",
    "character = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`|~กขฃคฅฆงจฉชซฌญฎฏฐฑฒณดตถทธนบปผฝพฟภมยรฤลฦวศษสหฬอฮฯะัาำิีึืุูเแโใไๅๆ็่้๊๋์ํ๐๑๒๓๔๕๖๗๘๙–‘ ’'\n",
    "separator_list = {}\n",
    "dict_list = {'en': 'd:\\\\Intern\\\\EasyOCR\\\\easyocr\\\\dict\\\\en.txt', 'th': 'd:\\\\Intern\\\\EasyOCR\\\\easyocr\\\\dict\\\\th.txt'}\n",
    "converter = CTCLabelConverter(character, separator_list, dict_list)\n",
    "pred_list = []\n",
    "gt = [] # ground truth\n",
    "name_img = []\n",
    "\n",
    "so = onnxruntime.SessionOptions()\n",
    "so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_session = onnxruntime.InferenceSession(\"rosetta_recognitionModel.onnx\", providers=['CUDAExecutionProvider', 'TensorrtExecutionProvider'], sess_options = so)\n",
    "ort_session.set_providers(['CUDAExecutionProvider', 'TensorrtExecutionProvider'])\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(\"crnn_recognitionModel.onnx\", providers=['TensorrtExecutionProvider', 'CPUExecutionProvider'])\n",
    "print(f'get_providers {ort_session.get_providers()} ')\n",
    "for i_img in tqdm(range(len(filepaths))):\n",
    "    label_img = label[i_img][1]\n",
    "    name_img.append(label[i_img][0])\n",
    "    result = onnx_recognize(filepaths[i_img], ort_session, converter)\n",
    "    \n",
    "    try:\n",
    "        pred_list.append([result[0][0]])\n",
    "    except:\n",
    "        pred_list.append('')\n",
    "    gt.append(label_img)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f'time: {end - start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaludate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = name_img.copy()\n",
    "output, false_list = eval_ocr_metric(pred_list, gt, tmp)\n",
    "# output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "for k,v in output.items():\n",
    "    print(f'{k}: {v}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52122cbc9699272b0fccdd336f01da0a8fa089bdcccefc5e05c668ba6be669f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
