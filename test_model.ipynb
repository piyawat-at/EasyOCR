{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import os\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from mmocr_eval import eval_ocr_metric\n",
    "import re\n",
    "import cv2 as cv\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/fulrose/how-to-apply-new-font-to-matplotlib-easily/notebook\n",
    "def change_matplotlib_font(font_download_url):\n",
    "    FONT_PATH = 'MY_FONT'\n",
    "\n",
    "    # font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
    "    # unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
    "    # os.system(font_download_cmd)\n",
    "    # os.system(unzip_cmd)\n",
    "\n",
    "\n",
    "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
    "    for font_file in font_files:\n",
    "        fm.fontManager.addfont(font_file)\n",
    "\n",
    "    try:\n",
    "        # print(font_files)\n",
    "        font_name = fm.FontProperties(fname=font_files[0]).get_name()\n",
    "    except:\n",
    "        print('Font not found')\n",
    "        font_name = 'Kanit'\n",
    "    matplotlib.rc('font', family=font_name)\n",
    "    print(\"font family: \", plt.rcParams['font.family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_download_url = 'https://fonts.google.com/download?family=Kanit'\n",
    "change_matplotlib_font(font_download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model by easyOCR API (https://www.jaided.ai/easyocr/documentation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# model = 'rosetta_hippo_300k_v1' #folder name of model\n",
    "# iteration = 'iter_30000' # model .pt file name\n",
    "\n",
    "# model_path = os.path.join('trainer', 'saved_models',model)\n",
    "# reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "#                     model_storage_directory = model_path,\n",
    "#                     user_network_directory = os.path.join('my_model','user_network'),\n",
    "#                     recog_network  = iteration,\n",
    "#                     config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "#                     gpu = True)\n",
    "# # reader = easyocr.Reader(lang_list = ['en','th'],gpu = True )\n",
    "# end = time.time()\n",
    "# print(f'loading model time: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualise testing with some image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_im = [789, 782, 575, 779, 589, 714, 999 ,683]\n",
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "\n",
    "# font_name = 'Kanit'\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# all_pred = []\n",
    "# columns = 4\n",
    "# rows = 4\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_path = random.sample(filepaths,1)[0]\n",
    "#     # random_file_path = filepaths[1]\n",
    "#     # random_file_path = filepaths[list_im.pop(0)]\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     all_pred.append(result[0][1])\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'{idx+1} predict: {txt}' , fontsize=20)\n",
    "#         # for i in boxs:\n",
    "#         #     pts = np.array(i, np.int32)\n",
    "#         #     pts = pts.reshape((-1,1,2))\n",
    "#         #     cv.polylines(img,[pts],True,(0,0,0))\n",
    "\n",
    "        \n",
    "#     else:\n",
    "#         ax[-1].set_title('No result', fontsize=20)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     label = np.loadtxt(file,dtype=str)\n",
    "# word_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = 5\n",
    "# rows = 200\n",
    "# fig, ax = plt.subplots(rows, columns, figsize=(20, 20))\n",
    "# ax.set_facecolor(\"white\")\n",
    "# counter = 0\n",
    "# for r in tqdm(range(rows)):\n",
    "#     for c in range(columns):\n",
    "#         file_name = re.split(r'[/\\\\]',filepaths[counter])[-1]\n",
    "#         file_path = os.path.join('trainer/all_data/testing/testing',file_name)\n",
    "#         img = plt.imread(file_path)\n",
    "#         ax[r, c].axis('off')\n",
    "#         result = reader.readtext(file_path) \n",
    "#         if len(result) > 0:\n",
    "#             txt = ''\n",
    "#             for i in result:\n",
    "#                 txt += (' '+i[1])\n",
    "#             ax[r, c].set_title(f'{file_name} predict: {txt}')\n",
    "#         else:\n",
    "#             ax[r, c].set_title('No result')\n",
    "#         ax[r, c].imshow(img)\n",
    "#         counter += 1\n",
    "# plt.subplots_adjust(top = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with all files in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))[:1000]\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     label = np.loadtxt(file,dtype=str)\n",
    "\n",
    "# start = time.time()\n",
    "# # filepaths = filepaths[:3]\n",
    "# pred = []\n",
    "# gt = [] # ground truth\n",
    "# name_img = []\n",
    "# for i in tqdm(range(len(filepaths))):\n",
    "#     label_img = label[i][1]\n",
    "#     name_img.append(label[i][0])\n",
    "#     result = reader.recognize(filepaths[i],detail=0)\n",
    "#     try:\n",
    "#         pred.append(result)\n",
    "#     except:\n",
    "#         pred.append('')\n",
    "#     gt.append(label_img)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = name_img.copy()\n",
    "output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "for k,v in output.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualise testing with flase prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 3\n",
    "# rows = 5\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_name = random.sample(false_list,1)[0]\n",
    "#     random_file_name = random_file_name[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=20) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=20)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with LMWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 2\n",
    "# rows = 10\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# ax = []\n",
    "# for i in range(columns*rows):\n",
    "#     random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/LMWN')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_name = os.listdir(os.path.join('trainer/all_data/testing/LMWN'))[2]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/LMWN',random_file_name)\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path) \n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'predict: \"{result[0][1]}\" ', fontsize=10)\n",
    "#         # pts = np.array(result[0][0], np.int32)\n",
    "#         # pts = pts.reshape((-1,1,2))\n",
    "#         # cv.polylines(img,[pts],True,(255,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title('No result',fontsize=10)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with google ocr testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/google_ocr_test_images','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))[:1000]\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# label_path = 'trainer/all_data/testing/google_ocr_test_images/image.txt'\n",
    "# label= []\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     lines = file.readlines()\n",
    "#     for line in lines:\n",
    "#         label.append(eval(line))\n",
    "# start = time.time()\n",
    "# # filepaths = filepaths[:3]\n",
    "# pred = []\n",
    "# gt = [] # ground truth\n",
    "# name_img = []\n",
    "# for i in tqdm(range(len(filepaths))):\n",
    "#     label_img = label[i]['text']\n",
    "#     name_img.append(label[i]['filename'])\n",
    "#     result = reader.recognize(filepaths[i],detail=0)\n",
    "#     try:\n",
    "#         pred.append(result)\n",
    "#     except:\n",
    "#         pred.append('')\n",
    "#     gt.append(label_img)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = name_img.copy()\n",
    "# output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "# for k,v in output.items():\n",
    "#     print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 3\n",
    "# rows = 5\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_name = random.sample(false_list,1)[0]\n",
    "#     random_file_name = random_file_name[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/google_ocr_test_images',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=15) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=15)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, iteration):\n",
    "    reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "                    model_storage_directory = model_path,\n",
    "                    user_network_directory = os.path.join('my_model','user_network'),\n",
    "                    recog_network  = iteration,\n",
    "                    config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "                    gpu = True)\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_testset(reader, test_set):\n",
    "    filepaths = test_set\n",
    "    filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "    label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "    with open(label_path, encoding='utf8') as file:\n",
    "        label = np.loadtxt(file,dtype=str)\n",
    "\n",
    "    start = time.time()\n",
    "    # filepaths = filepaths[:3]\n",
    "    pred = []\n",
    "    gt = [] # ground truth\n",
    "    name_img = []\n",
    "    for i in tqdm(range(len(filepaths))):\n",
    "        label_img = label[i][1]\n",
    "        name_img.append(label[i][0])\n",
    "        result = reader.recognize(filepaths[i],detail=0)\n",
    "        try:\n",
    "            pred.append(result)\n",
    "        except:\n",
    "            pred.append('')\n",
    "        gt.append(label_img)\n",
    "    end = time.time()\n",
    "    print(f'time: {end - start}')\n",
    "    return pred, gt, name_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "model = 'rosetta_hippo_300k_v1' #folder name of model\n",
    "model_path = os.path.join('trainer', 'saved_models',model)\n",
    "test_set = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "files_list = os.listdir(model_path)\n",
    "\n",
    "result = {}\n",
    "for file in files_list:\n",
    "    if file.startswith('iter'):\n",
    "        iteration = file.split('.pth')[0]\n",
    "        reader = load_model(model_path, iteration)\n",
    "        pred, gt, name_img = test_all_testset(reader, test_set)\n",
    "        tmp = name_img.copy()\n",
    "        output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "        # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "        result[iteration] = output\n",
    "        clear_output(wait=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    print(f'{k}: {v[\"word_acc\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt = {'iter_18000': {'char_recall': 0.8387,\n",
    "#   'char_precision': 0.9379,\n",
    "#   'word_acc': 0.678,\n",
    "#   'word_acc_ignore_case': 0.697,\n",
    "#   'word_acc_ignore_case_symbol': 0.833,\n",
    "#   '1-N.E.D': 0.8863},\n",
    "#  'iter_30000': {'char_recall': 0.8719,\n",
    "#   'char_precision': 0.9815,\n",
    "#   'word_acc': 0.749,\n",
    "#   'word_acc_ignore_case': 0.761,\n",
    "#   'word_acc_ignore_case_symbol': 0.902,\n",
    "#   '1-N.E.D': 0.9391},\n",
    "#  'iter_20000': {'char_recall': 0.8552,\n",
    "#   'char_precision': 0.9726,\n",
    "#   'word_acc': 0.71,\n",
    "#   'word_acc_ignore_case': 0.721,\n",
    "#   'word_acc_ignore_case_symbol': 0.881,\n",
    "#   '1-N.E.D': 0.9263},\n",
    "#  'iter_26000': {'char_recall': 0.8516,\n",
    "#   'char_precision': 0.9774,\n",
    "#   'word_acc': 0.711,\n",
    "#   'word_acc_ignore_case': 0.724,\n",
    "#   'word_acc_ignore_case_symbol': 0.888,\n",
    "#   '1-N.E.D': 0.9295},\n",
    "#  'iter_10000': {'char_recall': 0.837,\n",
    "#   'char_precision': 0.9576,\n",
    "#   'word_acc': 0.62,\n",
    "#   'word_acc_ignore_case': 0.638,\n",
    "#   'word_acc_ignore_case_symbol': 0.851,\n",
    "#   '1-N.E.D': 0.918},\n",
    "#  'iter_28000': {'char_recall': 0.8672,\n",
    "#   'char_precision': 0.973,\n",
    "#   'word_acc': 0.728,\n",
    "#   'word_acc_ignore_case': 0.742,\n",
    "#   'word_acc_ignore_case_symbol': 0.89,\n",
    "#   '1-N.E.D': 0.9368},\n",
    "#  'iter_16000': {'char_recall': 0.8461,\n",
    "#   'char_precision': 0.9736,\n",
    "#   'word_acc': 0.683,\n",
    "#   'word_acc_ignore_case': 0.701,\n",
    "#   'word_acc_ignore_case_symbol': 0.884,\n",
    "#   '1-N.E.D': 0.9316},\n",
    "#  'iter_4000': {'char_recall': 0.6886,\n",
    "#   'char_precision': 0.9279,\n",
    "#   'word_acc': 0.346,\n",
    "#   'word_acc_ignore_case': 0.373,\n",
    "#   'word_acc_ignore_case_symbol': 0.726,\n",
    "#   '1-N.E.D': 0.8538},\n",
    "#  'iter_22000': {'char_recall': 0.8487,\n",
    "#   'char_precision': 0.98,\n",
    "#   'word_acc': 0.712,\n",
    "#   'word_acc_ignore_case': 0.725,\n",
    "#   'word_acc_ignore_case_symbol': 0.894,\n",
    "#   '1-N.E.D': 0.931},\n",
    "#  'iter_8000': {'char_recall': 0.7876,\n",
    "#   'char_precision': 0.949,\n",
    "#   'word_acc': 0.519,\n",
    "#   'word_acc_ignore_case': 0.536,\n",
    "#   'word_acc_ignore_case_symbol': 0.8,\n",
    "#   '1-N.E.D': 0.8955},\n",
    "#  'iter_14000': {'char_recall': 0.8393,\n",
    "#   'char_precision': 0.9623,\n",
    "#   'word_acc': 0.655,\n",
    "#   'word_acc_ignore_case': 0.674,\n",
    "#   'word_acc_ignore_case_symbol': 0.864,\n",
    "#   '1-N.E.D': 0.9219},\n",
    "#  'iter_12000': {'char_recall': 0.8231,\n",
    "#   'char_precision': 0.9652,\n",
    "#   'word_acc': 0.627,\n",
    "#   'word_acc_ignore_case': 0.649,\n",
    "#   'word_acc_ignore_case_symbol': 0.862,\n",
    "#   '1-N.E.D': 0.9184},\n",
    "#  'iter_24000': {'char_recall': 0.8666,\n",
    "#   'char_precision': 0.9801,\n",
    "#   'word_acc': 0.731,\n",
    "#   'word_acc_ignore_case': 0.743,\n",
    "#   'word_acc_ignore_case_symbol': 0.896,\n",
    "#   '1-N.E.D': 0.9364},\n",
    "#  'iter_6000': {'char_recall': 0.772,\n",
    "#   'char_precision': 0.9413,\n",
    "#   'word_acc': 0.485,\n",
    "#   'word_acc_ignore_case': 0.512,\n",
    "#   'word_acc_ignore_case_symbol': 0.785,\n",
    "#   '1-N.E.D': 0.8779},\n",
    "#  'iter_2000': {'char_recall': 0.5555,\n",
    "#   'char_precision': 0.7329,\n",
    "#   'word_acc': 0.118,\n",
    "#   'word_acc_ignore_case': 0.122,\n",
    "#   'word_acc_ignore_case_symbol': 0.542,\n",
    "#   '1-N.E.D': 0.7264}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# x = []\n",
    "# y = []\n",
    "# key_sorted = sorted(txt, key= lambda x: int(x.split('_')[1]))\n",
    "# for k in key_sorted:\n",
    "#     x.append(int(k.split('_')[1]))\n",
    "#     y.append(txt[k]['word_acc'])\n",
    "# plt.figure(figsize=(8, 6), dpi=80)\n",
    "# plt.plot(x,y)\n",
    "# plt.title('Word Accuracy vs Iteration')\n",
    "# plt.xlabel('Iteration')\n",
    "# plt.ylabel('Word Accuracy')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
