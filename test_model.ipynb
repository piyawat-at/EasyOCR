{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import os\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from mmocr_eval import eval_ocr_metric\n",
    "import re\n",
    "import cv2 as cv\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/fulrose/how-to-apply-new-font-to-matplotlib-easily/notebook\n",
    "def change_matplotlib_font(font_download_url):\n",
    "    FONT_PATH = 'MY_FONT'\n",
    "\n",
    "    # font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
    "    # unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
    "    # os.system(font_download_cmd)\n",
    "    # os.system(unzip_cmd)\n",
    "\n",
    "\n",
    "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
    "    for font_file in font_files:\n",
    "        fm.fontManager.addfont(font_file)\n",
    "\n",
    "    try:\n",
    "        # print(font_files)\n",
    "        font_name = fm.FontProperties(fname=font_files[0]).get_name()\n",
    "    except:\n",
    "        print('Font not found')\n",
    "        font_name = 'Kanit'\n",
    "    matplotlib.rc('font', family=font_name)\n",
    "    print(\"font family: \", plt.rcParams['font.family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_download_url = 'https://fonts.google.com/download?family=Kanit'\n",
    "change_matplotlib_font(font_download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model by easyOCR API (https://www.jaided.ai/easyocr/documentation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = 'crnn_100k_lr_25e-2' #folder name of model\n",
    "iteration = 'iter_30000' # model .pt file name\n",
    "\n",
    "model_path = os.path.join('trainer', 'saved_models',model)\n",
    "# reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "#                     model_storage_directory = model_path,\n",
    "#                     user_network_directory = os.path.join('my_model','user_network'),\n",
    "#                     recog_network  = iteration,\n",
    "#                     config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "#                     gpu = True)\n",
    "reader = easyocr.Reader(lang_list = ['en','th'],gpu = True )\n",
    "end = time.time()\n",
    "print(f'loading model time: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualise testing with some image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_im = [789, 782, 575, 779, 589, 714, 999 ,683]\n",
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "\n",
    "font_name = 'Kanit'\n",
    "plt.rcParams['xtick.labelsize'] = 20.0\n",
    "plt.rcParams['ytick.labelsize'] = 20.0\n",
    "all_pred = []\n",
    "columns = 4\n",
    "rows = 4\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = []\n",
    "for i in tqdm(range(columns*rows)):\n",
    "    # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "    # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "    #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "    random_file_path = random.sample(filepaths,1)[0]\n",
    "    # random_file_path = filepaths[1]\n",
    "    # random_file_path = filepaths[list_im.pop(0)]\n",
    "    img = plt.imread(random_file_path)\n",
    "    result = reader.recognize(random_file_path)\n",
    "    all_pred.append(result[0][1])\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "    boxs = []\n",
    "    txt = []\n",
    "    for idx,i in enumerate(result):\n",
    "        boxs.append(i[0])\n",
    "        txt.append(i[1])\n",
    "    plt.axis('off')\n",
    "    if len(result) > 0:\n",
    "        ax[-1].set_title(f'{idx+1} predict: {txt}' , fontsize=20)\n",
    "        # for i in boxs:\n",
    "        #     pts = np.array(i, np.int32)\n",
    "        #     pts = pts.reshape((-1,1,2))\n",
    "        #     cv.polylines(img,[pts],True,(0,0,0))\n",
    "\n",
    "        \n",
    "    else:\n",
    "        ax[-1].set_title('No result', fontsize=20)\n",
    "    plt.imshow(img)\n",
    "fig.tight_layout() \n",
    "plt.show()\n",
    "print(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "with open(label_path, encoding='utf8') as file:\n",
    "    label = np.loadtxt(file,dtype=str)\n",
    "word_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = 5\n",
    "# rows = 200\n",
    "# fig, ax = plt.subplots(rows, columns, figsize=(20, 20))\n",
    "# ax.set_facecolor(\"white\")\n",
    "# counter = 0\n",
    "# for r in tqdm(range(rows)):\n",
    "#     for c in range(columns):\n",
    "#         file_name = re.split(r'[/\\\\]',filepaths[counter])[-1]\n",
    "#         file_path = os.path.join('trainer/all_data/testing/testing',file_name)\n",
    "#         img = plt.imread(file_path)\n",
    "#         ax[r, c].axis('off')\n",
    "#         result = reader.readtext(file_path) \n",
    "#         if len(result) > 0:\n",
    "#             txt = ''\n",
    "#             for i in result:\n",
    "#                 txt += (' '+i[1])\n",
    "#             ax[r, c].set_title(f'{file_name} predict: {txt}')\n",
    "#         else:\n",
    "#             ax[r, c].set_title('No result')\n",
    "#         ax[r, c].imshow(img)\n",
    "#         counter += 1\n",
    "# plt.subplots_adjust(top = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with all files in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))[:1000]\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     label = np.loadtxt(file,dtype=str)\n",
    "\n",
    "# start = time.time()\n",
    "# # filepaths = filepaths[:3]\n",
    "# pred = []\n",
    "# gt = [] # ground truth\n",
    "# name_img = []\n",
    "# for i in tqdm(range(len(filepaths))):\n",
    "#     label_img = label[i][1]\n",
    "#     name_img.append(label[i][0])\n",
    "#     result = reader.recognize(filepaths[i],detail=0)\n",
    "#     try:\n",
    "#         pred.append(result)\n",
    "#     except:\n",
    "#         pred.append('')\n",
    "#     gt.append(label_img)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = name_img.copy()\n",
    "# output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "# for k,v in output.items():\n",
    "#     print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualise testing with flase prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 3\n",
    "# rows = 5\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_name = random.sample(false_list,1)[0]\n",
    "#     random_file_name = random_file_name[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=20) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=20)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with LMWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 2\n",
    "# rows = 10\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# ax = []\n",
    "# for i in range(columns*rows):\n",
    "#     random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/LMWN')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_name = os.listdir(os.path.join('trainer/all_data/testing/LMWN'))[2]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/LMWN',random_file_name)\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path) \n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'predict: \"{result[0][1]}\" ', fontsize=10)\n",
    "#         # pts = np.array(result[0][0], np.int32)\n",
    "#         # pts = pts.reshape((-1,1,2))\n",
    "#         # cv.polylines(img,[pts],True,(255,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title('No result',fontsize=10)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with google ocr testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/google_ocr_test_images','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))[:1000]\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# label_path = 'trainer/all_data/testing/google_ocr_test_images/image.txt'\n",
    "# label= []\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     lines = file.readlines()\n",
    "#     for line in lines:\n",
    "#         label.append(eval(line))\n",
    "# start = time.time()\n",
    "# # filepaths = filepaths[:3]\n",
    "# pred = []\n",
    "# gt = [] # ground truth\n",
    "# name_img = []\n",
    "# for i in tqdm(range(len(filepaths))):\n",
    "#     label_img = label[i]['text']\n",
    "#     name_img.append(label[i]['filename'])\n",
    "#     result = reader.recognize(filepaths[i],detail=0)\n",
    "#     try:\n",
    "#         pred.append(result)\n",
    "#     except:\n",
    "#         pred.append('')\n",
    "#     gt.append(label_img)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = name_img.copy()\n",
    "# output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "# for k,v in output.items():\n",
    "#     print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 3\n",
    "# rows = 5\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_name = random.sample(false_list,1)[0]\n",
    "#     random_file_name = random_file_name[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/google_ocr_test_images',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=15) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=15)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, iteration):\n",
    "    reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "                    model_storage_directory = model_path,\n",
    "                    user_network_directory = os.path.join('my_model','user_network'),\n",
    "                    recog_network  = iteration,\n",
    "                    config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "                    gpu = True)\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_all_testset(reader):\n",
    "#     filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "#     filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "#     label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "#     with open(label_path, encoding='utf8') as file:\n",
    "#         label = np.loadtxt(file,dtype=str)\n",
    "\n",
    "#     start = time.time()\n",
    "#     # filepaths = filepaths[:3]\n",
    "#     pred = []\n",
    "#     gt = [] # ground truth\n",
    "#     name_img = []\n",
    "#     for i in tqdm(range(len(filepaths))):\n",
    "#         label_img = label[i][1]\n",
    "#         name_img.append(label[i][0])\n",
    "#         result = reader.recognize(filepaths[i],detail=0)\n",
    "#         try:\n",
    "#             pred.append(result)\n",
    "#         except:\n",
    "#             pred.append('')\n",
    "#         gt.append(label_img)\n",
    "#     end = time.time()\n",
    "#     print(f'time: {end - start}')\n",
    "#     return pred, gt, name_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from IPython.display import clear_output\n",
    "# model = 'crnn_100k_lr_25e-2' #folder name of model\n",
    "# model_path = os.path.join('trainer', 'saved_models',model)\n",
    "\n",
    "# files_list = os.listdir(model_path)\n",
    "\n",
    "# result = {}\n",
    "# for file in files_list:\n",
    "#     if file.startswith('iter'):\n",
    "#         iteration = file.split('.pth')[0]\n",
    "#         reader = load_model(model_path, iteration)\n",
    "#         pred, gt, name_img = test_all_testset(reader)\n",
    "#         tmp = name_img.copy()\n",
    "#         output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "#         # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "#         result[iteration] = output\n",
    "#         clear_output(wait=True)\n",
    "# ic(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in result.items():\n",
    "#     print(f'{k}: {v[\"word_acc\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = {'iter_18000': {'char_recall': 0.9089,\n",
    "  'char_precision': 0.9404,\n",
    "  'word_acc': 0.694,\n",
    "  'word_acc_ignore_case': 0.705,\n",
    "  'word_acc_ignore_case_symbol': 0.819,\n",
    "  '1-N.E.D': 0.8929},\n",
    " 'iter_30000': {'char_recall': 0.9001,\n",
    "  'char_precision': 0.9572,\n",
    "  'word_acc': 0.778,\n",
    "  'word_acc_ignore_case': 0.786,\n",
    "  'word_acc_ignore_case_symbol': 0.875,\n",
    "  '1-N.E.D': 0.9208},\n",
    " 'iter_20000': {'char_recall': 0.8954,\n",
    "  'char_precision': 0.9658,\n",
    "  'word_acc': 0.74,\n",
    "  'word_acc_ignore_case': 0.749,\n",
    "  'word_acc_ignore_case_symbol': 0.874,\n",
    "  '1-N.E.D': 0.9182},\n",
    " 'iter_26000': {'char_recall': 0.9163,\n",
    "  'char_precision': 0.9624,\n",
    "  'word_acc': 0.771,\n",
    "  'word_acc_ignore_case': 0.784,\n",
    "  'word_acc_ignore_case_symbol': 0.882,\n",
    "  '1-N.E.D': 0.9331},\n",
    " 'iter_10000': {'char_recall': 0.879,\n",
    "  'char_precision': 0.945,\n",
    "  'word_acc': 0.645,\n",
    "  'word_acc_ignore_case': 0.667,\n",
    "  'word_acc_ignore_case_symbol': 0.84,\n",
    "  '1-N.E.D': 0.9091},\n",
    " 'iter_28000': {'char_recall': 0.8989,\n",
    "  'char_precision': 0.9727,\n",
    "  'word_acc': 0.778,\n",
    "  'word_acc_ignore_case': 0.787,\n",
    "  'word_acc_ignore_case_symbol': 0.889,\n",
    "  '1-N.E.D': 0.928},\n",
    " 'iter_32000': {'char_recall': 0.9177,\n",
    "  'char_precision': 0.9612,\n",
    "  'word_acc': 0.813,\n",
    "  'word_acc_ignore_case': 0.824,\n",
    "  'word_acc_ignore_case_symbol': 0.896,\n",
    "  '1-N.E.D': 0.9336},\n",
    " 'iter_16000': {'char_recall': 0.9028,\n",
    "  'char_precision': 0.9621,\n",
    "  'word_acc': 0.772,\n",
    "  'word_acc_ignore_case': 0.778,\n",
    "  'word_acc_ignore_case_symbol': 0.882,\n",
    "  '1-N.E.D': 0.932},\n",
    " 'iter_4000': {'char_recall': 0.7782,\n",
    "  'char_precision': 0.9182,\n",
    "  'word_acc': 0.404,\n",
    "  'word_acc_ignore_case': 0.426,\n",
    "  'word_acc_ignore_case_symbol': 0.683,\n",
    "  '1-N.E.D': 0.8424},\n",
    " 'iter_22000': {'char_recall': 0.9031,\n",
    "  'char_precision': 0.9538,\n",
    "  'word_acc': 0.756,\n",
    "  'word_acc_ignore_case': 0.765,\n",
    "  'word_acc_ignore_case_symbol': 0.86,\n",
    "  '1-N.E.D': 0.9113},\n",
    " 'iter_8000': {'char_recall': 0.8546,\n",
    "  'char_precision': 0.9629,\n",
    "  'word_acc': 0.622,\n",
    "  'word_acc_ignore_case': 0.642,\n",
    "  'word_acc_ignore_case_symbol': 0.826,\n",
    "  '1-N.E.D': 0.92},\n",
    " 'iter_14000': {'char_recall': 0.8937,\n",
    "  'char_precision': 0.9509,\n",
    "  'word_acc': 0.704,\n",
    "  'word_acc_ignore_case': 0.719,\n",
    "  'word_acc_ignore_case_symbol': 0.86,\n",
    "  '1-N.E.D': 0.9207},\n",
    " 'iter_12000': {'char_recall': 0.8643,\n",
    "  'char_precision': 0.9614,\n",
    "  'word_acc': 0.641,\n",
    "  'word_acc_ignore_case': 0.676,\n",
    "  'word_acc_ignore_case_symbol': 0.853,\n",
    "  '1-N.E.D': 0.9151},\n",
    " 'iter_24000': {'char_recall': 0.9033,\n",
    "  'char_precision': 0.9784,\n",
    "  'word_acc': 0.812,\n",
    "  'word_acc_ignore_case': 0.817,\n",
    "  'word_acc_ignore_case_symbol': 0.905,\n",
    "  '1-N.E.D': 0.945},\n",
    " 'iter_6000': {'char_recall': 0.8499,\n",
    "  'char_precision': 0.9326,\n",
    "  'word_acc': 0.526,\n",
    "  'word_acc_ignore_case': 0.552,\n",
    "  'word_acc_ignore_case_symbol': 0.781,\n",
    "  '1-N.E.D': 0.8894},\n",
    " 'iter_2000': {'char_recall': 0.5429,\n",
    "  'char_precision': 0.8213,\n",
    "  'word_acc': 0.08,\n",
    "  'word_acc_ignore_case': 0.09,\n",
    "  'word_acc_ignore_case_symbol': 0.484,\n",
    "  '1-N.E.D': 0.7085}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = []\n",
    "y = []\n",
    "key_sorted = sorted(txt, key= lambda x: int(x.split('_')[1]))\n",
    "for k in key_sorted:\n",
    "    x.append(int(k.split('_')[1]))\n",
    "    y.append(txt[k]['word_acc'])\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.plot(x,y)\n",
    "plt.title('Word Accuracy vs Iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Word Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = {'iter_10000': {'1-N.E.D': 0.9003,\n",
    "                            'char_precision': 0.942,\n",
    "                            'char_recall': 0.844,\n",
    "                            'word_acc': 0.513,\n",
    "                            'word_acc_ignore_case': 0.547,\n",
    "                            'word_acc_ignore_case_symbol': 0.817},\n",
    "             'iter_12000': {'1-N.E.D': 0.9013,\n",
    "                            'char_precision': 0.9471,\n",
    "                            'char_recall': 0.8622,\n",
    "                            'word_acc': 0.6,\n",
    "                            'word_acc_ignore_case': 0.623,\n",
    "                            'word_acc_ignore_case_symbol': 0.838},\n",
    "             'iter_14000': {'1-N.E.D': 0.9238,\n",
    "                            'char_precision': 0.9668,\n",
    "                            'char_recall': 0.8563,\n",
    "                            'word_acc': 0.605,\n",
    "                            'word_acc_ignore_case': 0.637,\n",
    "                            'word_acc_ignore_case_symbol': 0.865},\n",
    "             'iter_16000': {'1-N.E.D': 0.9231,\n",
    "                            'char_precision': 0.9547,\n",
    "                            'char_recall': 0.8725,\n",
    "                            'word_acc': 0.629,\n",
    "                            'word_acc_ignore_case': 0.646,\n",
    "                            'word_acc_ignore_case_symbol': 0.864},\n",
    "             'iter_18000': {'1-N.E.D': 0.9142,\n",
    "                            'char_precision': 0.9562,\n",
    "                            'char_recall': 0.8666,\n",
    "                            'word_acc': 0.686,\n",
    "                            'word_acc_ignore_case': 0.697,\n",
    "                            'word_acc_ignore_case_symbol': 0.864},\n",
    "             'iter_2000': {'1-N.E.D': 0.4499,\n",
    "                           'char_precision': 0.3657,\n",
    "                           'char_recall': 0.0676,\n",
    "                           'word_acc': 0.0,\n",
    "                           'word_acc_ignore_case': 0.0,\n",
    "                           'word_acc_ignore_case_symbol': 0.413},\n",
    "             'iter_20000': {'1-N.E.D': 0.9064,\n",
    "                            'char_precision': 0.9567,\n",
    "                            'char_recall': 0.869,\n",
    "                            'word_acc': 0.673,\n",
    "                            'word_acc_ignore_case': 0.688,\n",
    "                            'word_acc_ignore_case_symbol': 0.855},\n",
    "             'iter_22000': {'1-N.E.D': 0.9378,\n",
    "                            'char_precision': 0.9747,\n",
    "                            'char_recall': 0.8731,\n",
    "                            'word_acc': 0.715,\n",
    "                            'word_acc_ignore_case': 0.728,\n",
    "                            'word_acc_ignore_case_symbol': 0.896},\n",
    "             'iter_24000': {'1-N.E.D': 0.9069,\n",
    "                            'char_precision': 0.9573,\n",
    "                            'char_recall': 0.8631,\n",
    "                            'word_acc': 0.708,\n",
    "                            'word_acc_ignore_case': 0.724,\n",
    "                            'word_acc_ignore_case_symbol': 0.857},\n",
    "             'iter_26000': {'1-N.E.D': 0.9403,\n",
    "                            'char_precision': 0.98,\n",
    "                            'char_recall': 0.8778,\n",
    "                            'word_acc': 0.707,\n",
    "                            'word_acc_ignore_case': 0.717,\n",
    "                            'word_acc_ignore_case_symbol': 0.902},\n",
    "             'iter_28000': {'1-N.E.D': 0.9286,\n",
    "                            'char_precision': 0.9616,\n",
    "                            'char_recall': 0.8907,\n",
    "                            'word_acc': 0.706,\n",
    "                            'word_acc_ignore_case': 0.72,\n",
    "                            'word_acc_ignore_case_symbol': 0.889},\n",
    "             'iter_30000': {'1-N.E.D': 0.9091,\n",
    "                            'char_precision': 0.9588,\n",
    "                            'char_recall': 0.8749,\n",
    "                            'word_acc': 0.737,\n",
    "                            'word_acc_ignore_case': 0.745,\n",
    "                            'word_acc_ignore_case_symbol': 0.877},\n",
    "             'iter_32000': {'1-N.E.D': 0.9235,\n",
    "                            'char_precision': 0.9592,\n",
    "                            'char_recall': 0.8898,\n",
    "                            'word_acc': 0.736,\n",
    "                            'word_acc_ignore_case': 0.744,\n",
    "                            'word_acc_ignore_case_symbol': 0.885},\n",
    "             'iter_34000': {'1-N.E.D': 0.9431,\n",
    "                            'char_precision': 0.9801,\n",
    "                            'char_recall': 0.8828,\n",
    "                            'word_acc': 0.765,\n",
    "                            'word_acc_ignore_case': 0.772,\n",
    "                            'word_acc_ignore_case_symbol': 0.906},\n",
    "             'iter_4000': {'1-N.E.D': 0.6686,\n",
    "                           'char_precision': 0.73,\n",
    "                           'char_recall': 0.5911,\n",
    "                           'word_acc': 0.124,\n",
    "                           'word_acc_ignore_case': 0.133,\n",
    "                           'word_acc_ignore_case_symbol': 0.473},\n",
    "             'iter_6000': {'1-N.E.D': 0.848,\n",
    "                           'char_precision': 0.8945,\n",
    "                           'char_recall': 0.7397,\n",
    "                           'word_acc': 0.337,\n",
    "                           'word_acc_ignore_case': 0.353,\n",
    "                           'word_acc_ignore_case_symbol': 0.717},\n",
    "             'iter_8000': {'1-N.E.D': 0.8632,\n",
    "                           'char_precision': 0.9066,\n",
    "                           'char_recall': 0.8096,\n",
    "                           'word_acc': 0.435,\n",
    "                           'word_acc_ignore_case': 0.465,\n",
    "                           'word_acc_ignore_case_symbol': 0.754}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = []\n",
    "y = []\n",
    "key_sorted = sorted(txt, key= lambda x: int(x.split('_')[1]))\n",
    "for k in key_sorted:\n",
    "    x.append(int(k.split('_')[1]))\n",
    "    y.append(txt[k]['word_acc'])\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.plot(x,y)\n",
    "plt.title('Word Accuracy vs Iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Word Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
