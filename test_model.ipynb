{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import os\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from mmocr_eval import eval_ocr_metric\n",
    "import re\n",
    "import cv2 as cv\n",
    "from icecream import ic\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Font install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/fulrose/how-to-apply-new-font-to-matplotlib-easily/notebook\n",
    "def change_matplotlib_font(font_download_url):\n",
    "    FONT_PATH = 'MY_FONT'\n",
    "\n",
    "    # font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
    "    # unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
    "    # os.system(font_download_cmd)\n",
    "    # os.system(unzip_cmd)\n",
    "\n",
    "\n",
    "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
    "    for font_file in font_files:\n",
    "        fm.fontManager.addfont(font_file)\n",
    "\n",
    "    try:\n",
    "        # print(font_files)\n",
    "        font_name = fm.FontProperties(fname=font_files[0]).get_name()\n",
    "    except:\n",
    "        print('Font not found')\n",
    "        font_name = 'Kanit'\n",
    "    matplotlib.rc('font', family=font_name)\n",
    "    print(\"font family: \", plt.rcParams['font.family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_download_url = 'https://fonts.google.com/download?family=Kanit'\n",
    "change_matplotlib_font(font_download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model by easyOCR API (https://www.jaided.ai/easyocr/documentation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# model = 'rosetta_hippo_300k_bw' #folder name of model\n",
    "# iteration = 'iter_36000' # model .pt file name\n",
    "\n",
    "# model_path = os.path.join('trainer', 'saved_models',model)\n",
    "# reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "#                     model_storage_directory = model_path,\n",
    "#                     user_network_directory = os.path.join('my_model','user_network'),\n",
    "#                     recog_network  = iteration,\n",
    "#                     config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "#                     gpu = True)\n",
    "# # reader = easyocr.Reader(lang_list = ['en','th'],gpu = True )\n",
    "# end = time.time()\n",
    "# print(f'loading model time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# model = 'crnn_hippo_1M' #folder name of model\n",
    "# iteration = 'iter_80000' # model .pt file name\n",
    "\n",
    "# model_path = os.path.join('trainer', 'saved_models',model)\n",
    "# reader2 = easyocr.Reader(lang_list = ['en','th'],\n",
    "#                     model_storage_directory = model_path,\n",
    "#                     user_network_directory = os.path.join('my_model','user_network'),\n",
    "#                     recog_network  = iteration,\n",
    "#                     config_path = 'crnn_1M', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "#                     gpu = True)\n",
    "# # reader = easyocr.Reader(lang_list = ['en','th'],gpu = True )\n",
    "# end = time.time()\n",
    "# print(f'loading model time: {end - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRDG testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize all trdg testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_im = [789, 782, 575, 779, 589, 714, 999 ,683]\n",
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "\n",
    "# font_name = 'Kanit'\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# all_pred = []\n",
    "# columns = 4\n",
    "# rows = 4\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_path = random.sample(filepaths,1)[0]\n",
    "#     # random_file_path = filepaths[1]\n",
    "#     # random_file_path = filepaths[list_im.pop(0)]\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     all_pred.append(result[0][1])\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'{idx+1} predict: {txt}' , fontsize=20)\n",
    "#         # for i in boxs:\n",
    "#         #     pts = np.array(i, np.int32)\n",
    "#         #     pts = pts.reshape((-1,1,2))\n",
    "#         #     cv.polylines(img,[pts],True,(0,0,0))\n",
    "\n",
    "        \n",
    "#     else:\n",
    "#         ax[-1].set_title('No result', fontsize=20)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     label = np.loadtxt(file,dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = 5\n",
    "# rows = 200\n",
    "# fig, ax = plt.subplots(rows, columns, figsize=(20, 20))\n",
    "# ax.set_facecolor(\"white\")\n",
    "# counter = 0\n",
    "# for r in tqdm(range(rows)):\n",
    "#     for c in range(columns):\n",
    "#         file_name = re.split(r'[/\\\\]',filepaths[counter])[-1]\n",
    "#         file_path = os.path.join('trainer/all_data/testing/testing',file_name)\n",
    "#         img = plt.imread(file_path)\n",
    "#         ax[r, c].axis('off')\n",
    "#         result = reader.readtext(file_path) \n",
    "#         if len(result) > 0:\n",
    "#             txt = ''\n",
    "#             for i in result:\n",
    "#                 txt += (' '+i[1])\n",
    "#             ax[r, c].set_title(f'{file_name} predict: {txt}')\n",
    "#         else:\n",
    "#             ax[r, c].set_title('No result')\n",
    "#         ax[r, c].imshow(img)\n",
    "#         counter += 1\n",
    "# plt.subplots_adjust(top = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with trdg testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))[:1000]\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     label = np.loadtxt(file,dtype=str)\n",
    "\n",
    "# start = time.time()\n",
    "# # filepaths = filepaths[:3]\n",
    "# pred = []\n",
    "# gt = [] # ground truth\n",
    "# name_img = []\n",
    "# for i in tqdm(range(len(filepaths))):\n",
    "#     label_img = label[i][1]\n",
    "#     name_img.append(label[i][0])\n",
    "#     result = reader.recognize(filepaths[i],detail=0)\n",
    "#     try:\n",
    "#         pred.append(result)\n",
    "#     except:\n",
    "#         pred.append('')\n",
    "#     gt.append(label_img)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = name_img.copy()\n",
    "# output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "# for k,v in output.items():\n",
    "#     print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples testing with flase prediction from trdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 3\n",
    "# rows = 5\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_name = random.sample(false_list,1)[0]\n",
    "#     random_file_name = random_file_name[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=20) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=20)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMWN testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samepls with LMWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 2\n",
    "# rows = 10\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# ax = []\n",
    "# for i in range(columns*rows):\n",
    "#     random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/LMWN')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_name = os.listdir(os.path.join('trainer/all_data/testing/LMWN'))[2]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/LMWN',random_file_name)\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path) \n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1))\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'predict: \"{result[0][1]}\" ', fontsize=10)\n",
    "#         # pts = np.array(result[0][0], np.int32)\n",
    "#         # pts = pts.reshape((-1,1,2))\n",
    "#         # cv.polylines(img,[pts],True,(255,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title('No result',fontsize=10)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google OCR testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples with google ocr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 2\n",
    "# rows = 10\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/google_ocr_test_images')),1)[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/google_ocr_test_images',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=15) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=15)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with google ocr testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths = glob.glob(os.path.join('trainer/all_data/testing/google_ocr_test_images','*.jpg'))\n",
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))[:1000]\n",
    "# filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# label_path = 'trainer/all_data/testing/google_ocr_test_images/image.txt'\n",
    "# label= []\n",
    "# with open(label_path, encoding='utf8') as file:\n",
    "#     lines = file.readlines()\n",
    "#     for line in lines:\n",
    "#         label.append(eval(line))\n",
    "# start = time.time()\n",
    "# # filepaths = filepaths[:3]\n",
    "# pred = []\n",
    "# gt = [] # ground truth\n",
    "# name_img = []\n",
    "# print(len(filepaths), len(label))\n",
    "# for i in tqdm(range(len(filepaths))):\n",
    "#     label_img = label[i]['text']\n",
    "#     name_img.append(label[i]['filename'])\n",
    "#     result = reader.recognize(filepaths[i],detail=0)\n",
    "#     try:\n",
    "#         pred.append(result)\n",
    "#     except:\n",
    "#         pred.append('')\n",
    "#     gt.append(label_img)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = name_img.copy()\n",
    "# output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "# for k,v in output.items():\n",
    "#     print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples testing with flase prediction from google oce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 1\n",
    "# rows = 10\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "#     # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "#     #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "#     random_file_name = random.sample(false_list,1)[0]\n",
    "#     random_file_name = random_file_name[0]\n",
    "#     random_file_path = os.path.join('trainer/all_data/testing/google_ocr_test_images',random_file_name)\n",
    "\n",
    "#     img = plt.imread(random_file_path)\n",
    "#     result = reader.recognize(random_file_path)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=20) \n",
    "#         # for i in boxs:\n",
    "#         #         pts = np.array(i, np.int32)\n",
    "#         #         pts = pts.reshape((-1,1,2))\n",
    "#         #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: {random_file_name} No result', fontsize=20)\n",
    "#     plt.imshow(img)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIA testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samepls with aia (random image + random text box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 1\n",
    "# rows = 1\n",
    "# fig = plt.figure(figsize=(5, 5))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     filepaths_list = glob.glob(os.path.join('trainer/all_data/testing/data_aia_mmocr','*.jpg'))\n",
    "#     random_filepath = random.sample(filepaths_list,1)[0]\n",
    "\n",
    "#     img = plt.imread(random_filepath)\n",
    "#     box_pos_json = random_filepath+'.json'\n",
    "#     with open(box_pos_json, 'r') as f:\n",
    "#         box_pos = json.load(f)\n",
    "#     box_pos_random = random.sample(box_pos['result']['horizontal_box'],1)[0]\n",
    "#     crop = img[box_pos_random[2]:box_pos_random[3],box_pos_random[0]:box_pos_random[1]]\n",
    "\n",
    "#     result = reader.recognize(crop)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         # boxs.append(i[0])\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {idx}: {txt} ', fontsize=20) \n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: No result', fontsize=20)\n",
    "#     plt.imshow(crop)\n",
    "# fig.tight_layout() \n",
    "# plt.show()\n",
    "# print(all_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 model comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams['xtick.labelsize'] = 20.0\n",
    "# plt.rcParams['ytick.labelsize'] = 20.0\n",
    "# columns = 1\n",
    "# rows = 1\n",
    "# fig = plt.figure(figsize=(5, 5))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i in tqdm(range(columns*rows)):\n",
    "#     filepaths_list = glob.glob(os.path.join('trainer/all_data/testing/data_aia_mmocr','*.jpg'))\n",
    "#     random_filepath = random.sample(filepaths_list,1)[0]\n",
    "\n",
    "#     img = plt.imread(random_filepath)\n",
    "#     box_pos_json = random_filepath+'.json'\n",
    "#     with open(box_pos_json, 'r') as f:\n",
    "#         box_pos = json.load(f)\n",
    "#     box_pos_random = random.sample(box_pos['result']['horizontal_box'],1)[0]\n",
    "#     crop = img[box_pos_random[2]:box_pos_random[3],box_pos_random[0]:box_pos_random[1]]\n",
    "\n",
    "#     result = reader.recognize(crop)\n",
    "#     result2 = reader2.recognize(crop)\n",
    "#     ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "#     # boxs = []\n",
    "#     txt = []\n",
    "#     txt2 = []\n",
    "#     for idx,i in enumerate(zip(result,result2)):\n",
    "#         txt.append(i[0][1])\n",
    "#         txt2.append(i[1][1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     if len(result) > 0:\n",
    "#         # ax[-1].set_title(f'file: {idx}: {txt} {txt2}', fontsize=20) \n",
    "#         filename = re.split(r'[/\\\\.]',random_filepath)[-2]\n",
    "#         ax[-1].set_title(f'file: {filename}', fontsize=20)\n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: No result', fontsize=20)\n",
    "#     plt.imshow(crop)\n",
    "# plt.show()\n",
    "# print(f'   rosetta {txt}')\n",
    "# print(f'   crnn    {txt2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samepls with aia (random image + all text box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths_list = glob.glob(os.path.join('trainer/all_data/testing/data_aia_mmocr','*.jpg'))\n",
    "# random_filepath = random.sample(filepaths_list,1)[0]\n",
    "# img = plt.imread(random_filepath)\n",
    "# box_pos_json = random_filepath+'.json'\n",
    "# with open(box_pos_json, 'r') as f:\n",
    "#     box_pos = json.load(f)\n",
    "# box_count = len(box_pos['result']['horizontal_box'])\n",
    "# col = 2\n",
    "# row = int(box_count/col)+1\n",
    "# fig = plt.figure(figsize=(15, 15))\n",
    "# ax = []\n",
    "# all_pred = []\n",
    "# for i_box, box in enumerate(tqdm(box_pos['result']['horizontal_box'])):\n",
    "#     crop = img[box[2]:box[3],box[0]:box[1]]\n",
    "#     result = reader.recognize(crop)\n",
    "#     ax.append(fig.add_subplot(row, col, i_box+1) )\n",
    "#     txt = []\n",
    "#     for idx,i in enumerate(result):\n",
    "#         txt.append(i[1])\n",
    "#     all_pred.append(txt)\n",
    "#     plt.axis('off')\n",
    "#     if len(result) > 0:\n",
    "#         ax[-1].set_title(f'file: {idx}: {txt} ', fontsize=15) \n",
    "#     else:\n",
    "#         ax[-1].set_title(f'file: No result', fontsize=15)\n",
    "#     plt.imshow(crop)\n",
    "# fig.tight_layout()\n",
    "# fig = plt.figure(figsize=(10, 10))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# print(all_pred)\n",
    "# print(random_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing all iterations model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path, iteration):\n",
    "    reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "                    model_storage_directory = model_path,\n",
    "                    user_network_directory = os.path.join('my_model','user_network'),\n",
    "                    recog_network  = iteration,\n",
    "                    config_path = 'crnn', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "                    gpu = True)\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_all_testset(reader, test_set_path, test_set_label):\n",
    "    filepaths = test_set_path\n",
    "    filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "    label_path = test_set_label\n",
    "    try:\n",
    "        with open(label_path, encoding='utf8') as file:\n",
    "                label = np.loadtxt(file,dtype=str)\n",
    "    except:\n",
    "        with open(label_path, encoding='utf8') as file:\n",
    "            label = []\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                label.append(eval(line))\n",
    "            \n",
    "\n",
    "    start = time.time()\n",
    "    # filepaths = filepaths[:3]\n",
    "    pred = []\n",
    "    gt = [] # ground truth\n",
    "    name_img = []\n",
    "    for i in range(len(filepaths)):\n",
    "        try:\n",
    "            label_img = label[i][1]\n",
    "            name_img.append(label[i][0])\n",
    "        except:\n",
    "            label_img = label[i]['text']\n",
    "            name_img.append(label[i]['filename'])\n",
    "        \n",
    "        result = reader.recognize(filepaths[i],detail=0)\n",
    "        try:\n",
    "            pred.append(result)\n",
    "        except:\n",
    "            pred.append('')\n",
    "        gt.append(label_img)\n",
    "    end = time.time()\n",
    "    print(f'time: {end - start}')\n",
    "    return pred, gt, name_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with trdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result_loop = []\n",
    "with open('loop_result_300k_bw.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        result_loop.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "model = 'rosetta_hippo_300k_bw' #folder name of model\n",
    "model_path = os.path.join('trainer', 'saved_models',model)\n",
    "test_set = 'testing'\n",
    "test_set_path = glob.glob(os.path.join('trainer/all_data/testing/',test_set,'*.jpg'))\n",
    "test_set_label = os.path.join('trainer/all_data/testing/',test_set,'label.txt')\n",
    "files_list = os.listdir(model_path)\n",
    "result = {}\n",
    "testing_list = []\n",
    "print(f'!!!!!!! model name : {model} !!!!!!!')\n",
    "for i_file,r in enumerate(result_loop):\n",
    "    if r[0] == model and r[1] == 'trdg': \n",
    "        testing_list = r.copy()\n",
    "        break\n",
    "\n",
    "max_ = 0\n",
    "if len(testing_list[2]) > 0:\n",
    "    for i in eval(testing_list[2]):\n",
    "        cur = int(i.split('_')[1])\n",
    "        if cur > max_:\n",
    "            max_ = cur\n",
    "files_list = [i for i in files_list if i.startswith('iter') and int(i.split('.')[0].split('_')[1]) > max_]\n",
    "print(len(files_list))\n",
    "for file in tqdm(files_list):\n",
    "    iteration = file.split('.pth')[0]\n",
    "    reader = load_model(model_path, iteration)\n",
    "    pred, gt, name_img = test_all_testset(reader, test_set_path, test_set_label)\n",
    "    tmp = name_img.copy()\n",
    "    output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "    # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "    result[iteration] = output\n",
    "    clear_output(wait=True)\n",
    "    # pbar.update(1)\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    print(f'{k}: {v[\"word_acc\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with google ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result_loop = []\n",
    "with open('loop_result_300k_bw.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        result_loop.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "model = 'rosetta_hippo_300k_bw' #folder name of model\n",
    "model_path = os.path.join('trainer', 'saved_models',model)\n",
    "test_set = 'google_ocr_test_images'\n",
    "test_set_path = glob.glob(os.path.join('trainer/all_data/testing/',test_set,'*.jpg'))\n",
    "if test_set == 'google_ocr_test_images':\n",
    "    test_set_label = os.path.join('trainer/all_data/testing/',test_set,'image.txt')\n",
    "else :\n",
    "    test_set_label = os.path.join('trainer/all_data/testing/',test_set,'label.txt')\n",
    "files_list = os.listdir(model_path)\n",
    "\n",
    "result = {}\n",
    "testing_list = []\n",
    "print(f'!!!!!!! model name : {model} !!!!!!!')\n",
    "for i_file,r in enumerate(result_loop):\n",
    "    if r[0] == model and r[1] == 'google': \n",
    "        testing_list = r.copy()\n",
    "        break\n",
    "max_ = 0\n",
    "if len(testing_list[2]) > 0:\n",
    "    for i in eval(testing_list[2]):\n",
    "        cur = int(i.split('_')[1])\n",
    "        if cur > max_:\n",
    "            max_ = cur\n",
    "files_list = [i for i in files_list if i.startswith('iter') and int(i.split('.')[0].split('_')[1]) > max_]\n",
    "print(len(files_list))\n",
    "for file in tqdm(files_list):\n",
    "    iteration = file.split('.pth')[0]\n",
    "    reader = load_model(model_path, iteration)\n",
    "    pred, gt, name_img = test_all_testset(reader, test_set_path, test_set_label)\n",
    "    tmp = name_img.copy()\n",
    "    output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "    # output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "    result[iteration] = output\n",
    "    clear_output(wait=True)\n",
    "    # pbar.update(1)\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    print(f'{k}: {v[\"word_acc\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result_loop = []\n",
    "with open('loop_result_300k_bw.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        result_loop.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(result_loop[i_file][2]) > 0:\n",
    "    old_result = eval(result_loop[i_file][2])\n",
    "    new_result = old_result.copy()\n",
    "    for k,v in result.items():\n",
    "        new_result[k] = v\n",
    "else:\n",
    "    new_result = result.copy()\n",
    "len(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(result_loop[i_file])\n",
    "result_loop[i_file][2] = str(new_result)\n",
    "with open('loop_result_300k_bw.csv', 'w') as file:\n",
    "    for i in result_loop:\n",
    "        file.write(f'{i[0]},{i[1]},\"{i[2]}\"'+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in result.items():\n",
    "    print(f'{k}: {v[\"word_acc\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysis word accuracy vs iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_loop = []\n",
    "# with open('loop_result.csv', 'a') as file:\n",
    "#     file.writeline('test1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "result_loop = []\n",
    "with open('loop_result_300k_bw.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        result_loop.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = 0\n",
    "\n",
    "# txt = eval(result_loop[row][2])\n",
    "# model_name = result_loop[row][0]\n",
    "# testset_name = result_loop[row][1]\n",
    "# print(f'{model_name} {testset_name}')\n",
    "# print(txt['iter_2000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "columns = 2\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i in range(len(result_loop)):\n",
    "    x = []\n",
    "    y = []\n",
    "    txt = eval(result_loop[i][2])\n",
    "    model_name = result_loop[i][0]\n",
    "    testset_name = result_loop[i][1]\n",
    "    key_sorted = sorted(txt, key= lambda x: int(x.split('_')[1]))\n",
    "    for k in key_sorted:\n",
    "        x.append(int(k.split('_')[1]))\n",
    "        y.append(txt[k]['word_acc'])\n",
    "    if len(y) > 0:\n",
    "        print(f'{model_name} {testset_name} {x[y.index(max(y))]} {max(y)}')\n",
    "        plt.plot(x,y)\n",
    "    if i % 2 == 1:\n",
    "        plt.title(f'model name: {model_name}\\n Word Accuracy vs Iteration')\n",
    "        plt.legend([result_loop[i-1][1], result_loop[i][1]], loc =\"lower right\")\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Word Accuracy')\n",
    "        plt.show()\n",
    "        fig = plt.figure(figsize=(12, 8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
