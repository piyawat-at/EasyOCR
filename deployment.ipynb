{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import os\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "from mmocr_eval import eval_ocr_metric\n",
    "import re\n",
    "import cv2 as cv\n",
    "import onnxruntime\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx\n",
    "# !pip a onnxruntime-gpu\n",
    "# !pip install icecream\n",
    "# !pip install matplotlib\n",
    "# !pip install rapidfuzz\n",
    "# !pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/fulrose/how-to-apply-new-font-to-matplotlib-easily/notebook\n",
    "def change_matplotlib_font(font_download_url):\n",
    "    FONT_PATH = 'MY_FONT'\n",
    "\n",
    "    # font_download_cmd = f\"wget {font_download_url} -O {FONT_PATH}.zip\"\n",
    "    # unzip_cmd = f\"unzip -o {FONT_PATH}.zip -d {FONT_PATH}\"\n",
    "    # os.system(font_download_cmd)\n",
    "    # os.system(unzip_cmd)\n",
    "\n",
    "\n",
    "    font_files = fm.findSystemFonts(fontpaths=FONT_PATH)\n",
    "    for font_file in font_files:\n",
    "        fm.fontManager.addfont(font_file)\n",
    "\n",
    "    try:\n",
    "        # print(font_files)\n",
    "        font_name = fm.FontProperties(fname=font_files[0]).get_name()\n",
    "    except:\n",
    "        print('Font not found')\n",
    "        font_name = 'Kanit'\n",
    "    matplotlib.rc('font', family=font_name)\n",
    "    print(\"font family: \", plt.rcParams['font.family'])\n",
    "font_download_url = 'https://fonts.google.com/download?family=Kanit'\n",
    "change_matplotlib_font(font_download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load pth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'rosetta_300k_synthtiger' #folder name of model\n",
    "# iteration = 'iter_70000' # model .pt file name\n",
    "\n",
    "# model_path = os.path.join('trainer', 'saved_models',model)\n",
    "# reader = easyocr.Reader(lang_list = ['en','th'],\n",
    "#                     model_storage_directory = model_path,\n",
    "#                     user_network_directory = os.path.join('my_model','user_network'),\n",
    "#                     recog_network  = iteration,\n",
    "#                     config_path = 'hippo_300k_synthtiger', #configuration file name use to get character_list only  (so able to use for every model)\n",
    "#                     gpu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction with pth model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run this cell and edit config in deployment_config.py to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# # filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "# # # random_file_path = filepaths[10]\n",
    "# # random_file_path = random.sample(filepaths,1)[0]\n",
    "# random_file_path = '10.jpg'\n",
    "# img = plt.imread(random_file_path)\n",
    "# # print (f'image befor reader: {img[0][0]}')\n",
    "# start = time.time()\n",
    "# result = reader.recognize(random_file_path)\n",
    "# end = time.time()\n",
    "# print(f'time: {end - start}')\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prediction with onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from easyocr.utils import reformat_input\n",
    "from easyocr.utils import get_image_list\n",
    "from easyocr.recognition import AlignCollate\n",
    "from easyocr.recognition import ListDataset\n",
    "import torch.nn.functional as F\n",
    "from easyocr.utils import CTCLabelConverter\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy()if tensor.requires_grad else tensor.cpu().numpy()\n",
    "def custom_mean(x):\n",
    "    return x.prod()**(2.0/np.sqrt(len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_recognize(img_path, ort_session, converter, device = torch.device(\"cuda\")):\n",
    "    # start = time.time()\n",
    "    img, img_cv_grey = reformat_input(img_path)\n",
    "    y_max, x_max = img_cv_grey.shape\n",
    "    horizontal_list = [[0, x_max, 0, y_max]]\n",
    "    for bbox in horizontal_list:\n",
    "                    h_list = [bbox]\n",
    "                    f_list = []\n",
    "                    image_list, max_width = get_image_list(h_list, f_list, img_cv_grey, model_height = 64)\n",
    "\n",
    "    img_list = [item[1] for item in image_list]\n",
    "\n",
    "    AlignCollate_normal = AlignCollate(imgH=64, imgW=600, keep_ratio_with_pad=True)\n",
    "    test_data = ListDataset(img_list)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, batch_size=1, shuffle=False,\n",
    "            num_workers=int(0), collate_fn=AlignCollate_normal, pin_memory=True)\n",
    "    \n",
    "    image_tensors = next(iter(test_loader))\n",
    "    batch_size = image_tensors.size(0)\n",
    "    image = image_tensors.to(device)\n",
    "    # end = time.time()\n",
    "    # print(f'pre-process : {end - start}')\n",
    "\n",
    "    # start = time.time()\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(image)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    preds = torch.from_numpy(ort_outs[0])\n",
    "    # end = time.time()\n",
    "    # print(f'prediction : {end - start}')\n",
    "\n",
    "    ignore_idx = []\n",
    "    start = time.time()\n",
    "    # Select max probabilty (greedy decoding) then decode index to character\n",
    "    preds_size = torch.IntTensor([preds.size(1)] * batch_size)\n",
    "\n",
    "    ######## filter ignore_char, rebalance\n",
    "    preds_prob = F.softmax(preds, dim=2)\n",
    "    preds_prob = preds_prob.cpu().detach().numpy()\n",
    "    preds_prob[:,:,ignore_idx] = 0.\n",
    "    pred_norm = preds_prob.sum(axis=2)\n",
    "    preds_prob = preds_prob/np.expand_dims(pred_norm, axis=-1)\n",
    "    preds_prob = torch.from_numpy(preds_prob).float().to(device)\n",
    "    result = []\n",
    "\n",
    "    # end = time.time()\n",
    "    # print(f'preds_prob : {end - start}')\n",
    "    # decoder\n",
    "    decoder = 'greedy'\n",
    "    if decoder == 'greedy':\n",
    "        # Select max probabilty (greedy decoding) then decode index to character\n",
    "        _, preds_index = preds_prob.max(2)\n",
    "        preds_index = preds_index.view(-1)\n",
    "        preds_str = converter.decode_greedy(preds_index.data.cpu().detach().numpy(), preds_size.data)\n",
    "    elif decoder == 'beamsearch':\n",
    "        k = preds_prob.cpu().detach().numpy()\n",
    "        preds_str = converter.decode_beamsearch(k, beamWidth=5)\n",
    "    elif decoder == 'wordbeamsearch':\n",
    "        k = preds_prob.cpu().detach().numpy()\n",
    "        preds_str = converter.decode_wordbeamsearch(k, beamWidth=5)\n",
    "\n",
    "    # end = time.time()\n",
    "    # print(f'decoder : {end - start}')\n",
    "    preds_prob = preds_prob.cpu().detach().numpy()\n",
    "    values = preds_prob.max(axis=2)\n",
    "    indices = preds_prob.argmax(axis=2)\n",
    "    preds_max_prob = []\n",
    "    for v,i in zip(values, indices):\n",
    "        max_probs = v[i!=0]\n",
    "        if len(max_probs)>0:\n",
    "            preds_max_prob.append(max_probs)\n",
    "        else:\n",
    "            preds_max_prob.append(np.array([0]))\n",
    "\n",
    "    for pred, pred_max_prob in zip(preds_str, preds_max_prob):\n",
    "        confidence_score = custom_mean(pred_max_prob)\n",
    "        result.append([pred, confidence_score])\n",
    "    # end = time.time()\n",
    "    # print(f'post-process : {end - start}')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"rosetta_hippo_300k_bw_recognitionModel.onnx\", providers=['CUDAExecutionProvider'])\n",
    "ort_session.get_providers()\n",
    "ort_session.set_providers(['CUDAExecutionProvider'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict with onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "file_path = '/home/EasyOCR/my_model/user_network/hippo_300k_synthtiger.yaml'\n",
    "with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character = opt['character_list']\n",
    "separator_list = {}\n",
    "dict_list = {}\n",
    "converter = CTCLabelConverter(character, separator_list, dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_file_path = '10.jpg'\n",
    "# random_file_path = filepaths[0]\n",
    "start = time.time()\n",
    "result = onnx_recognize(random_file_path, ort_session, converter)\n",
    "\n",
    "end = time.time()\n",
    "print(f'time: {end - start}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing with 1000 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "label_path = 'trainer/all_data/testing/testing/label.txt'\n",
    "with open(label_path, encoding='utf8') as file:\n",
    "    label = np.loadtxt(file,dtype=str)\n",
    "start = time.time()\n",
    "pred_list = []\n",
    "gt = [] # ground truth\n",
    "name_img = []\n",
    "\n",
    "so = onnxruntime.SessionOptions()\n",
    "so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_session = onnxruntime.InferenceSession(\"rosetta_hippo_300k_bw_recognitionModel.onnx\", providers=['CUDAExecutionProvider'], sess_options = so)\n",
    "ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "\n",
    "# ort_session = onnxruntime.InferenceSession(\"crnn_recognitionModel.onnx\", providers=['TensorrtExecutionProvider', 'CPUExecutionProvider'])\n",
    "print(f'get_providers {ort_session.get_providers()} ')\n",
    "for i_img in tqdm(range(len(filepaths))):\n",
    "    label_img = label[i_img][1]\n",
    "    name_img.append(label[i_img][0])\n",
    "    result = onnx_recognize(filepaths[i_img], ort_session, converter)\n",
    "    \n",
    "    try:\n",
    "        pred_list.append([result[0][0]])\n",
    "    except:\n",
    "        pred_list.append('')\n",
    "    gt.append(label_img)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(f'time: {end - start}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaludate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = name_img.copy()\n",
    "output, false_list = eval_ocr_metric(pred_list, gt, tmp)\n",
    "# output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "for k,v in output.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 20.0\n",
    "plt.rcParams['ytick.labelsize'] = 20.0\n",
    "columns = 3\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = []\n",
    "all_pred = []\n",
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/testing','*.jpg'))\n",
    "# filepaths = glob.glob(os.path.join('trainer/all_data/training/training','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "for i in tqdm(range(columns*rows)):\n",
    "    # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "    # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "    #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "    random_file_name = random.sample(filepaths,1)[0]\n",
    "    random_file_path = random_file_name\n",
    "\n",
    "    so = onnxruntime.SessionOptions()\n",
    "    so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    ort_session = onnxruntime.InferenceSession(\"rosetta_recognitionModel.onnx\", providers=['CUDAExecutionProvider'], sess_options = so)\n",
    "    ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "\n",
    "    img = plt.imread(random_file_path)\n",
    "    result = onnx_recognize(random_file_path, ort_session, converter)\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "    # boxs = []\n",
    "    txt = []\n",
    "    for idx,i in enumerate(result):\n",
    "        # boxs.append(i[0])\n",
    "        txt.append(i[0])\n",
    "    all_pred.append(txt)\n",
    "    plt.axis('off')\n",
    "    if len(result) > 0:\n",
    "        ax[-1].set_title(f'{idx}: {txt} ', fontsize=15) \n",
    "        # for i in boxs:\n",
    "        #         pts = np.array(i, np.int32)\n",
    "        #         pts = pts.reshape((-1,1,2))\n",
    "        #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "    else:\n",
    "        ax[-1].set_title(f'file: {random_file_name} No result', fontsize=15)\n",
    "    plt.imshow(img)\n",
    "fig.tight_layout() \n",
    "plt.show()\n",
    "print(all_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['xtick.labelsize'] = 20.0\n",
    "plt.rcParams['ytick.labelsize'] = 20.0\n",
    "columns = 3\n",
    "rows = 1\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "ax = []\n",
    "all_pred = []\n",
    "for i in tqdm(range(columns*rows)):\n",
    "    # random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "    # random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "    #random_file_name = random.sample(os.listdir(os.path.join('trainer/all_data/testing/testing')),1)[0]\n",
    "\n",
    "    random_file_name = random.sample(false_list,1)[0]\n",
    "    random_file_name = random_file_name[0]\n",
    "    random_file_path = os.path.join('trainer/all_data/testing/testing',random_file_name)\n",
    "\n",
    "    so = onnxruntime.SessionOptions()\n",
    "    so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    ort_session = onnxruntime.InferenceSession(\"rosetta_recognitionModel.onnx\", providers=['CUDAExecutionProvider'], sess_options = so)\n",
    "    ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "\n",
    "    img = plt.imread(random_file_path)\n",
    "    result = onnx_recognize(random_file_path, ort_session, converter)\n",
    "    ax.append(fig.add_subplot(rows, columns, i+1) )\n",
    "    # boxs = []\n",
    "    txt = []\n",
    "    for idx,i in enumerate(result):\n",
    "        # boxs.append(i[0])\n",
    "        txt.append(i[0])\n",
    "    all_pred.append(txt)\n",
    "    plt.axis('off')\n",
    "    if len(result) > 0:\n",
    "        ax[-1].set_title(f'file: {random_file_name} {idx}: {txt} ', fontsize=15) \n",
    "        # for i in boxs:\n",
    "        #         pts = np.array(i, np.int32)\n",
    "        #         pts = pts.reshape((-1,1,2))\n",
    "        #         cv.polylines(img,[pts],True,(0,0,0))\n",
    "    else:\n",
    "        ax[-1].set_title(f'file: {random_file_name} No result', fontsize=15)\n",
    "    plt.imshow(img)\n",
    "fig.tight_layout() \n",
    "plt.show()\n",
    "print(all_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join('trainer/all_data/testing/test_bw','*.jpg'))\n",
    "filepaths = sorted(filepaths, key= lambda x: int(re.split(r'[/\\\\.]',x)[-2]))\n",
    "label_path = 'trainer/all_data/testing/test_bw/label.txt'\n",
    "label= []\n",
    "with open(label_path, encoding='utf8') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        label.append(eval(line))\n",
    "start = time.time()\n",
    "# filepaths = filepaths[:3]\n",
    "pred = []\n",
    "gt = [] # ground truth\n",
    "name_img = []\n",
    "so = onnxruntime.SessionOptions()\n",
    "so.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "ort_session = onnxruntime.InferenceSession(\"rosetta_hippo_300k_bw_recognitionModel.onnx\", providers=['CUDAExecutionProvider'], sess_options = so)\n",
    "ort_session.set_providers(['CUDAExecutionProvider'])\n",
    "print(len(filepaths), len(label))\n",
    "for i in tqdm(range(len(filepaths))):\n",
    "    label_img = label[i]['text']\n",
    "    name_img.append(label[i]['filename'])\n",
    "    result = onnx_recognize(filepaths[i], ort_session, converter)\n",
    "    try:\n",
    "        pred.append([result[0][0]])\n",
    "    except:\n",
    "        pred.append('')\n",
    "    gt.append(label_img)\n",
    "end = time.time()\n",
    "print(f'time: {end - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = name_img.copy()\n",
    "output, false_list = eval_ocr_metric(pred, gt, tmp)\n",
    "# output, false_list = eval_ocr_metric(pred, gt, name_img)\n",
    "for k,v in output.items():\n",
    "    print(f'{k}: {v}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
