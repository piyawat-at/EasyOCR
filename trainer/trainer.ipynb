{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch\n",
    "import yaml\n",
    "from utils import AttrDict\n",
    "import pandas as pd\n",
    "from train import train\n",
    "from data_prepare import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install natsort\n",
    "# !pip install torchvision\n",
    "# !pip install pyyaml\n",
    "# !pip install pandas\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.885144Z",
     "start_time": "2021-07-23T04:19:23.880564Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = raw_data_path = os.path.join('raw_data','train_images_30k')\n",
    "# prepare_data(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:24.119144Z",
     "start_time": "2021-07-23T04:19:24.112032Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        pass\n",
    "        # characters = ''\n",
    "        # for data in opt['select_data'].split('-'):\n",
    "        #     csv_path = os.path.join(opt['train_data'], 'training' ,data, 'labels.csv')\n",
    "        #     df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "        #     all_char = ''.join(df['words'])\n",
    "        #     characters += ''.join(set(all_char))\n",
    "        # characters = sorted(set(characters))\n",
    "        # opt.character= ''.join(characters)\n",
    "        # print('char: ',opt.character)\n",
    "    else:\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], 'training' ,data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "        print(f'experiment: {opt.experiment_name}')\n",
    "        print('char in train_set:',opt.character)\n",
    "        opt.character = opt.lang_char\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "albe to config in config_files/*.yaml\n",
    "check list: \\\n",
    "&emsp;lang_char \\\n",
    "&emsp;experiment_name \\\n",
    "&emsp;num_iter \\\n",
    "&emsp;saved_model \\\n",
    "&emsp;lr \\\n",
    "&emsp;model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:49:07.045060Z",
     "start_time": "2021-07-23T04:20:15.050992Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = get_config(\"config_files/crnn_30k.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = [ './saved_models/crnn_30k_lr_5e-1/log_loss_train.txt',\n",
    "]\n",
    "loss_list = []\n",
    "for path in label_path:\n",
    "    with open(path, encoding='utf8') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            if not line.startswith('experiment_name'):\n",
    "                loss_list.append(float(line.split(' ')[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(len(loss_list))\n",
    "batch_size = 32\n",
    "iteration = len(loss_list)*10\n",
    "epoch = (iteration*batch_size) // 26859\n",
    "epoch_avg = np.array([])\n",
    "for i in range(epoch):\n",
    "    epoch_avg = np.append(epoch_avg, np.mean(loss_list[int(i*26859/320):(i+1)*int(i*26859/320)]))\n",
    "plt.figure(figsize=(10, 10), dpi=80)\n",
    "start_row = 0\n",
    "start = int(start_row /10)\n",
    "# plt.plot(np.arange(len(loss_list[start:]))*10+start_row, loss_list[start:])\n",
    "plt.plot(epoch_avg[:])\n",
    "# plt.title(f'Training loss afer {start_row} iterations')\n",
    "plt.title(f'Training loss')\n",
    "plt.xlabel('iterations')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "52122cbc9699272b0fccdd336f01da0a8fa089bdcccefc5e05c668ba6be669f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
